{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f75bd6",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a07d76b",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Gary\\\\workspace\\\\LangGraph_agent_test\\\\scr\\\\tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263c8f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tavily-python in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (0.7.12)\n",
      "Requirement already satisfied: requests in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from tavily-python) (2.32.5)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from tavily-python) (0.11.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from tiktoken>=0.5.1->tavily-python) (2025.9.18)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from requests->tavily-python) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from requests->tavily-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from requests->tavily-python) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from requests->tavily-python) (2025.8.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from httpx->tavily-python) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from anyio->httpx->tavily-python) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tavily-python\n",
    "\n",
    "import os\n",
    "from flask.cli import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "from tavily_tool import tavily_tool\n",
    "from count_tokens import count_tokens\n",
    "from google_search import google_search\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()  \n",
    "\n",
    "# Load API keys from environment variable\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "# Initialize the OpenAI chat model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4531a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state for the graph, using TypedDict for type safety\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Create a new state graph for the conversation\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# List of tools to be used by the model\n",
    "agent_tools = [tavily_tool, google_search]\n",
    "\n",
    "# Bind the tools to the language model that the LLM can use to answer user queries\n",
    "llm_with_tools = llm.bind_tools(agent_tools)\n",
    "\n",
    "# Define the chatbot node logic\n",
    "def chatbot(state: State):\n",
    "    # The chatbot node invokes the model with the current messages\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Create and add the tool node to the graph\n",
    "tool_node = ToolNode(tools=agent_tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(\"count_tokens\", ToolNode(tools=[count_tokens])) # Add a separate node for the count_tokens tool as it must run last\n",
    "\n",
    "\n",
    "# Add conditional edges: if a tool is needed, go to the tool node\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Start the graph at the chatbot node\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# After using a tool, return to the chatbot node\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", \"count_tokens\")\n",
    "# End the graph after the count_tokens node\n",
    "graph_builder.add_edge(\"count_tokens\", END)\n",
    "# Compile the graph for execution\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd2e23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grandalf\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\gary\\workspace\\langgraph_agent_test\\py_dev\\lib\\site-packages (from grandalf) (3.2.5)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Installing collected packages: grandalf\n",
      "Successfully installed grandalf-0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec4165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    +-----------+                 \n",
      "                    | __start__ |                 \n",
      "                    +-----------+                 \n",
      "                          *                       \n",
      "                          *                       \n",
      "                          *                       \n",
      "                     +---------+                  \n",
      "                     | chatbot |                  \n",
      "                  ***+---------+....              \n",
      "              ****        *         ....          \n",
      "          ****            *             ...       \n",
      "        **                *                ....   \n",
      "+-------+         +--------------+             .. \n",
      "| tools |         | count_tokens |            ..  \n",
      "+-------+         +--------------+          ..    \n",
      "                               **         ..      \n",
      "                                 **     ..        \n",
      "                                   *   .          \n",
      "                                +---------+       \n",
      "                                | __end__ |       \n",
      "                                +---------+       \n"
     ]
    }
   ],
   "source": [
    "# draw the graph\n",
    "#from IPython.display import Image, display\n",
    "#from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "#import pyppeteer\n",
    "\n",
    "print(graph.get_graph().draw_ascii())\n",
    "#print(graph.get_graph().draw_mermaid())\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef186b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest stock market crash is widely considered to be the Wall Street Crash of 1929, also known as the Great Crash. It began in late October 1929, with the most significant declines occurring on October 24th (Black Thursday), October 28th (Black Monday), and October 29th (Black Tuesday). The crash was triggered by a combination of speculative bubble, excessive use of margin (borrowing to buy stocks), and panic selling. It marked the start of the Great Depression.\n",
      "\n",
      "Answer from Tavily: The largest stock market crash is typically identified as the Wall Street Crash of 1929, which led to the Great Depression. The crash was driven by speculation, over-leveraged investments, low confidence, and panic selling. : source https://www.investopedia.com/articles/07/marketcrash.asp\n",
      "\n",
      "Answer from Google Search: The Wall Street Crash of 1929 is considered the biggest stock market crash in history, largely caused by speculation, credit expansion, and loss of confidence. : source https://www.history.com/topics/great-depression/1929-stock-market-crash\n",
      "\n",
      "Tool (Tokens used: 149, Characters used: 1062). LLM (Tokens used: 151).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_prompt = SystemMessage(\n",
    "    content=(\n",
    "        \"Answer the user question and be concise. Respond with only the essential information.\"\n",
    "        \"Use both the Tavily and Google Search tools to find the answer. \"\n",
    "        \"In your answer, cite both results separately and show their source. \"\n",
    "        \"Also include a details of token usage and the total number of characters used at the end of your answer\" \n",
    "        \" Your reply should follow the format below:\"\n",
    "        \" <Answer to the user question> \"\n",
    "        \" \"\n",
    "        \" <Answer from Tavily> : source <URL> \"\n",
    "        \" <Answer from Google Search> : source <URL> \"\n",
    "        \" \"\n",
    "        \" Tool (Tokens used: <estimated_token_count>, Characters used: <character_count>). These values must be obtained from the count_tokens tool without alteration.\"\n",
    "        \" LLM (Tokens used: <total_tokens>). This information must be obtained from the LLM response looking for the response metadata for the total_tokens values.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "question = HumanMessage(content=\"What was the largest stock market crash and why?\")\n",
    "\n",
    "# Prepend the system prompt to the messages\n",
    "messages = [system_prompt, question]\n",
    "\n",
    "# Invoke the graph with the initial messages\n",
    "answer = graph.invoke({\"messages\": messages})\n",
    "\n",
    "\n",
    "print(answer[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
